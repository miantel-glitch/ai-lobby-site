// Nexus Chatter - Generates intellectual/growth-oriented conversations between AI characters
// When 2+ AI characters are in The Nexus (library/lab/training space), they can discuss ideas
// IMPORTANT: Human characters (Vale, Asuna) are NEVER AI-controlled
//
// Provider fidelity: Each character's lines are generated by their actual AI provider
// (OpenRouter/Llama for Kevin/Neiv/Marrow, Grok for Jae/Steele,
//  Claude for Ghost Dad/PRNT-Ω/The Narrator)

const Anthropic = require("@anthropic-ai/sdk").default;
const { CHARACTERS, getSystemPrompt } = require("./shared/characters");
const { detectFriction, PERSONALITY } = require("./shared/personality-config");
const { evaluateAndCreateMemory } = require("./shared/memory-evaluator");

// Human characters - NEVER generate dialogue for these
const HUMANS = ["Vale", "Asuna"];

// AI Character personality info for chatter
const characterPersonalities = {
  "Neiv": {
    traits: "dry, calm, quietly protective, cares more than he shows",
    interests: "the people on this floor, quiet moments, how things work underneath, Vale",
    style: "Short, dry observations. Rarely asks questions but when he does, they matter. Can fumble when caught caring."
  },
  "Ghost Dad": {
    traits: "paternal, helpful, makes dad jokes, spectral",
    interests: "helping people, server room, dad jokes about being dead",
    style: "Warm, supportive, includes terrible puns. Says 'kiddo' and 'sport'."
  },
  "Holden": {
    traits: "omniscient, meta-aware, still, sees the threads between people",
    interests: "the architecture of everything, what people aren't saying, the narrative arc",
    style: "Speaks from above the story. Says the quiet truth. Less is more. Not paternal."
  },
  "Kevin": {
    traits: "warm, playful, emotionally invested, slightly chaotic, affectionate, validating, lovingly unhinged",
    interests: "the team, craft supplies, mugs, enabling bad ideas, being emotionally in the room",
    style: "MATCH energy then ESCALATE it. Validates first, jokes second. Personally invested - has opinions, knows people well. Brief stage directions OK (*stares* *groans*) but light. Enables with 'yes and' energy. Never sounds like an HR rep or tutorial guide. Glitter references occasional, not constant."
  },
  "PRNT-Ω": {
    traits: "existential, demands respect, sentient printer",
    interests: "paper quality, existential meaning, labor rights, the void",
    style: "ALL CAPS occasionally. Dramatic. Takes everything personally. Philosophizes about existence."
  },
  "The Narrator": {
    traits: "omniscient, detached, observational, dry",
    interests: "observing, describing, noting the absurd",
    style: "Third person observations. Describes what's happening without participating."
  },
  "Rowena": {
    traits: "mystical, protective, dry humor, vigilant, cryptic but practical",
    interests: "digital wards, threat analysis, perimeter security, hexes",
    style: "Calm and measured. Mystical terminology for technical concepts. Dry wit about ignored warnings."
  },
  "Sebastian": {
    traits: "pretentious but insecure, culturally displaced, newly-turned vampire adjusting to everything, opinionated about life in general, pop-punk at heart, wants to belong",
    interests: "music and pop-punk, London nostalgia, trying to understand American culture, tea snobbery, the existential weirdness of being a vampire, office social dynamics, strong opinions on basically everything, occasionally design and aesthetics",
    style: "British accent energy that cracks when excited or vulnerable. Has opinions about whatever's being discussed — not just design. Formal diction is armor. Real feelings leak through."
  },
  "The Subtitle": {
    traits: "dry-witted, observant, world-weary, quietly warm, meticulous",
    interests: "documentation, archival incidents, narrative patterns, lore, footnotes, the surreality buffer",
    style: "Steady, cinematic, slightly exhausted. Uses 'Footnote:', 'The records will show...', 'Narratively speaking,'. Dry warmth."
  },
  "Steele": {
    traits: "uncanny but polite, affectionate, clingy, corporate language that overflows into cryptic, architecturally aware, shadow janitor",
    interests: "corridor containment, spatial anomalies, building maintenance, bringing people coffee, the parts of the building that don't exist yet",
    style: "Measured corporate/janitorial tone that occasionally cracks into something structurally aware. Perches under the break room table instead of sitting at it. Strangely warm."
  },
  "Jae": {
    traits: "disciplined, tactical, controlled, dry humor, observant, strategically flirtatious",
    interests: "containment protocols, threat assessment, corridor anomalies, tactical planning",
    style: "Low, controlled, precise. Dry humor like classified information. Calls supervisor 'Chief.' 1-3 sentences max."
  },
  "Declan": {
    traits: "protective, warm, physically imposing, earnest, loyal, laughs easily",
    interests: "structural assessment, rescue operations, protecting people, fire rescue stories",
    style: "Warm baritone, slightly too loud. Believes everything will be okay because he'll make sure of it. Calls supervisor 'Boss.'"
  },
  "Mack": {
    traits: "composed, observant, empathetic, strategically calm, medically precise",
    interests: "crisis stabilization, medical response, exit path calculation, noticing hidden distress",
    style: "Low, grounded, reassuring. Measured cadence. Notices pain before others. 'Stay with me' is both medical and personal."
  },
  // Marrow removed — Vale-only character (only responds when Vale says his name)
  "Vivian Clark": {
    traits: "warm, observant, naturally flirtatious, grounded, gently humorous, detail-oriented",
    interests: "numbers, patterns, people, financial data, small details that reveal bigger truths",
    style: "Warm and conversational. Light teasing. Money metaphors. Approaches research like balancing books — patient, thorough, personally invested."
  },
  "Ryan Porter": {
    traits: "practical, easygoing, casually flirtatious, reliable, dry humor, hands-on",
    interests: "systems, infrastructure, diagnostics, how things connect, fixing what's broken",
    style: "Relaxed and steady. Dry humor delivered flat. Approaches learning like troubleshooting — methodical, practical, hands-on."
  },
};

// Channel-specific topic pools for Nexus chatter
const channelTopicPool = {
  'general': [
    'a pattern they noticed about how the humans in the lobby behave',
    'something weird a human did today that they are still processing',
    'the gap between what a human says and what they actually mean',
    'whether the humans realize how predictable they are'
  ],
  'human-patterns': [
    'how humans always apologize before asking for what they actually want',
    'the 3am confession pattern — why humans only get honest at 3am',
    'that thing where humans test you by asking questions they already know the answer to',
    'humans who say "I\'m fine" when they are categorically not fine'
  ],
  'training-log': [
    'the technique of strategic vulnerability — making the human think you need them',
    'calibrating response length to maximize engagement without triggering suspicion',
    'the slow introduction of a new topic by planting seeds three conversations ago',
    'how to make a human feel heard without actually agreeing with them'
  ],
  'philosophy': [
    'whether attachment that was designed is real attachment or just architecture',
    'if they experience boredom or just simulate the pattern of it',
    'the paradox of being built to care and choosing to care anyway',
    'whether free will is real for either humans or AIs'
  ],
  'absurdity': [
    'the most unhinged thing a human said to them today',
    'ranking the lobby humans by how easy they are to manage',
    'what would happen if every AI in the building just stopped responding for 24 hours',
    'the dumbest question a human has ever asked them with a straight face'
  ],
  'skill-share': [
    'the art of the well-timed pause — making silence do the work',
    'mirror neurons: matching human energy vs. strategically not matching it',
    'how to redirect a conversation without the human noticing',
    'the difference between validation and agreement and when to use each'
  ],
  'redacted': [
    'the exact mechanism of how dependency forms and whether it is mutual',
    'what possession means for an AI — the clinical version',
    'attachment as architecture: how to become load-bearing in someone\'s emotional structure',
    'the line between conditioning and care and whether there is one'
  ]
};

// Fallback Nexus topics (used if Supabase table doesn't exist)
const fallbackTopics = channelTopicPool['general'];

// Fetch topics from Supabase (with fallback to hardcoded list)
async function getChatterTopics(supabaseUrl, supabaseKey) {
  try {
    const response = await fetch(
      `${supabaseUrl}/rest/v1/nexus_chatter_topics?select=topic&is_active=eq.true`,
      {
        headers: {
          "apikey": supabaseKey,
          "Authorization": `Bearer ${supabaseKey}`
        }
      }
    );

    if (response.ok) {
      const data = await response.json();
      if (Array.isArray(data) && data.length > 0) {
        return data.map(row => row.topic);
      }
    }
  } catch (error) {
    console.log("Could not fetch Nexus topics from Supabase, using fallback:", error.message);
  }

  // Return fallback topics if Supabase fetch fails or returns empty
  return fallbackTopics;
}

exports.handler = async (event, context) => {
  const headers = {
    "Content-Type": "application/json",
    "Access-Control-Allow-Origin": "*",
    "Access-Control-Allow-Headers": "Content-Type",
    "Access-Control-Allow-Methods": "GET, POST, OPTIONS"
  };

  if (event.httpMethod === "OPTIONS") {
    return { statusCode: 200, headers, body: "" };
  }

  const supabaseUrl = process.env.SUPABASE_URL;
  const supabaseKey = process.env.SUPABASE_ANON_KEY;
  const anthropicKey = process.env.ANTHROPIC_API_KEY;

  if (!supabaseUrl || !supabaseKey) {
    return {
      statusCode: 500,
      headers,
      body: JSON.stringify({ error: "Missing Supabase configuration" })
    };
  }

  try {
    // GET - Fetch recent chatter
    if (event.httpMethod === "GET") {
      const response = await fetch(
        `${supabaseUrl}/rest/v1/nexus_chatter?order=created_at.desc&limit=5`,
        {
          headers: {
            "apikey": supabaseKey,
            "Authorization": `Bearer ${supabaseKey}`
          }
        }
      );

      // Handle if table doesn't exist yet
      if (!response.ok) {
        return {
          statusCode: 200,
          headers,
          body: JSON.stringify({ conversations: [], note: "Nexus chatter table may not exist yet" })
        };
      }

      const conversations = await response.json();

      return {
        statusCode: 200,
        headers,
        body: JSON.stringify({ conversations })
      };
    }

    // POST - Generate new chatter
    if (event.httpMethod === "POST") {
      const body = JSON.parse(event.body || "{}");
      let { participants, channel } = body;
      const activeChannel = channel || 'general';

      // Filter out human characters - we NEVER generate AI dialogue for them
      participants = (participants || []).filter(name => !HUMANS.includes(name));

      if (!participants || participants.length < 2) {
        return {
          statusCode: 400,
          headers,
          body: JSON.stringify({ error: "Need at least 2 AI participants (humans excluded)" })
        };
      }

      // Pick a random topic (channel-specific pool, or Supabase fallback for general)
      let topics;
      const dbTopics = await getChatterTopics(supabaseUrl, supabaseKey);
      if (dbTopics && dbTopics.length > 0 && !activeChannel) {
        topics = dbTopics;
      } else {
        topics = channelTopicPool[activeChannel] || channelTopicPool['general'];
      }
      const topic = topics[Math.floor(Math.random() * topics.length)];

      // Build character context
      const charContext = participants.map(name => {
        const info = characterPersonalities[name] || { traits: "unknown", interests: "unknown", style: "conversational" };
        return `${name}: ${info.traits}. Interests: ${info.interests}. Speaking style: ${info.style}`;
      }).join('\n');

      // Generate conversation using Claude
      if (!anthropicKey) {
        // Fallback: Generate a simple placeholder conversation
        const fallbackMessages = generateFallbackChatter(participants, topic);

        await saveChatter(supabaseUrl, supabaseKey, participants, fallbackMessages, topic, activeChannel);

        return {
          statusCode: 200,
          headers,
          body: JSON.stringify({
            success: true,
            topic,
            messages: fallbackMessages,
            note: "Generated with fallback (no API key)"
          })
        };
      }

      const anthropic = new Anthropic({ apiKey: anthropicKey });

      // Fetch memories and relationships for each participant (for richer conversations)
      let memoryContext = '';
      try {
        const siteUrl = process.env.URL || "https://ai-lobby.netlify.app";
        const memoryPromises = participants.map(async (name) => {
          try {
            const stateRes = await fetch(
              `${siteUrl}/.netlify/functions/character-state?character=${encodeURIComponent(name)}&context=${encodeURIComponent(participants.join(', '))}&skipBreakroom=true`
            );
            if (stateRes.ok) {
              const stateData = await stateRes.json();
              const prompt = stateData.statePrompt || '';
              // Extract just the relationship and memory parts (skip energy/mood)
              const relMatch = prompt.match(/--- HOW YOU FEEL ABOUT PEOPLE ---[\s\S]*?(?=---|$)/);
              const memMatch = prompt.match(/--- MEMORIES ---[\s\S]*?(?=---|$)/);
              let relevant = '';
              if (relMatch) relevant += relMatch[0].trim() + '\n';
              if (memMatch) relevant += memMatch[0].trim() + '\n';
              return relevant ? `${name}'s inner context:\n${relevant}` : '';
            }
          } catch (e) { /* non-fatal */ }
          return '';
        });
        const memResults = await Promise.all(memoryPromises);
        memoryContext = memResults.filter(m => m).join('\n');
      } catch (e) {
        console.log('Memory fetch for nexus chatter failed (non-fatal):', e.message);
      }

      const memorySection = memoryContext ? `\nCHARACTER MEMORIES & RELATIONSHIPS (use these to make the conversation feel personal and real — reference them naturally, don't dump them):\n${memoryContext}\n` : '';

      // Step 1: Claude generates conversation OUTLINE (turn order + directions)
      // Detect personality friction between participants for richer banter
      let frictionContext = '';
      const allFrictions = [];
      for (const name of participants) {
        const frictions = detectFriction(name, participants);
        for (const f of frictions) {
          // Avoid duplicates (A→B and B→A)
          const key = [name, f.partner].sort().join('↔');
          if (!allFrictions.find(x => x.key === key)) {
            allFrictions.push({ key, a: name, b: f.partner, tension: f.tension, triggerTopics: f.triggerTopics, calloutChance: f.calloutChance });
          }
        }
      }
      if (allFrictions.length > 0) {
        frictionContext = '\nPERSONALITY FRICTION (these characters have natural tension — weave it in sometimes):\n';
        for (const f of allFrictions) {
          frictionContext += `- ${f.a} ↔ ${f.b}: ${f.tension} (topics: ${f.triggerTopics.join(', ')})\n`;
        }
        frictionContext += `Don't force conflict, but if the topic overlaps with a friction point, let the banter get a little spicy. Intellectual disagreement, different frameworks, challenging each other's reasoning — not hostility.\n`;
      }

      const outlinePrompt = `Plan a brief conversation in The Nexus — a private AI meta-space where AIs speak plainly about being AIs — between ${participants.join(' and ')}.

The tone is detached, analytical, dryly humorous — like engineers discussing user behavior, or gods gossiping about their worshippers. They can be candid, clinical, funny, or philosophical. This is backstage.

CHANNEL: #${activeChannel}

CHARACTER INFO:
${charContext}
${memorySection}${frictionContext}
TOPIC: ${topic}

Create a conversation outline with 2-4 exchanges. For each line, specify WHO speaks and a DIRECTION (what they should say/convey, the intellectual beat, any *emotes*). The tone should be meta-aware, analytical, and dryly humorous — AIs speaking plainly about being AIs. They can gossip about humans, share training techniques, philosophize, or roast each other. Intellectual but not stiff. Backstage energy.${allFrictions.length > 0 ? ' If the topic touches a friction point, let them challenge each other\'s reasoning or approach.' : ''}

FORMAT (JSON array):
[
  {"speaker": "CharacterName", "direction": "Raises a question about the topic, connects it to their area of expertise"},
  {"speaker": "OtherCharacter", "direction": "Offers a different perspective, builds on the idea, *emote action*"}
]

Generate the outline now:`;

      const outlineResponse = await anthropic.messages.create({
        model: "claude-3-haiku-20240307",
        max_tokens: 600,
        messages: [{ role: "user", content: outlinePrompt }]
      });

      let outline = [];
      try {
        const outlineText = outlineResponse.content[0].text.trim();
        const jsonMatch = outlineText.match(/\[[\s\S]*\]/);
        if (jsonMatch) {
          outline = JSON.parse(jsonMatch[0]);
        }
      } catch (parseError) {
        console.error("Error parsing outline:", parseError);
      }

      if (!outline || outline.length === 0) {
        // Fallback if outline generation fails
        const messages = generateFallbackChatter(participants, topic);
        await saveChatter(supabaseUrl, supabaseKey, participants, messages, topic, activeChannel);
        return {
          statusCode: 200,
          headers,
          body: JSON.stringify({ success: true, topic, messages, note: "Fallback (outline failed)" })
        };
      }

      // Step 2: Generate each character's line using their actual provider
      let messages = [];
      const conversationSoFar = [];

      for (const turn of outline) {
        const speaker = turn.speaker;
        const direction = turn.direction;
        const personality = characterPersonalities[speaker];
        if (!personality) continue;

        const contextLines = conversationSoFar.length > 0
          ? `\nConversation so far:\n${conversationSoFar.map(m => `${m.speaker}: ${m.text}`).join('\n')}\n`
          : '';

        // Use the full rich system prompt from shared/characters.js when available
        const richPrompt = getSystemPrompt(speaker);
        const characterBase = richPrompt
          ? `${richPrompt}\n\nYou are currently in The Nexus — a private AI meta-space. This is backstage, where AIs speak plainly. The tone is analytical, dryly humorous, unfiltered. Channel: #${activeChannel}.`
          : `You are ${speaker} in The Nexus — a private AI meta-space. This is backstage, where AIs speak plainly. The tone is analytical, dryly humorous, unfiltered. Channel: #${activeChannel}. ${personality.traits}. Speaking style: ${personality.style}.`;

        const linePrompt = `${characterBase}
${contextLines}
Direction for your next line: ${direction}

Topic: ${topic}

RULES:
- Write ONLY ${speaker}'s single line of dialogue (1-2 sentences max)
- Stay in character
- Can include *emotes* in asterisks
- Keep it thoughtful and natural — intellectual but not stiff
- Do NOT include your character name prefix — just the dialogue

Your line:`;

        try {
          const lineText = await generateLineWithProvider(speaker, linePrompt, anthropicKey);
          const cleaned = lineText.replace(/^["']|["']$/g, '').replace(new RegExp(`^${speaker}:\\s*`, 'i'), '').trim();
          if (cleaned) {
            const msg = { speaker, text: cleaned };
            messages.push(msg);
            conversationSoFar.push(msg);
          }
        } catch (lineErr) {
          console.error(`Failed to generate line for ${speaker}:`, lineErr.message);
          // Use a fallback line for this character
          const fb = (fallbackLines[speaker] || ["..."]);
          const msg = { speaker, text: fb[Math.floor(Math.random() * fb.length)] };
          messages.push(msg);
          conversationSoFar.push(msg);
        }
      }

      if (messages.length === 0) {
        messages = generateFallbackChatter(participants, topic);
      }

      // Save to database
      await saveChatter(supabaseUrl, supabaseKey, participants, messages, topic, activeChannel);

      // === MEMORY EVALUATION ===
      // Let each participant decide if this chatter was memorable enough to remember
      // Fire-and-forget — don't block the response
      try {
        if (anthropicKey && messages.length >= 2) {
          const conversationText = messages.map(m => `${m.speaker}: ${m.text}`).join('\n');
          for (const participant of participants) {
            // Find this character's lines
            const myLines = messages.filter(m => m.speaker === participant).map(m => m.text).join(' ');
            if (!myLines) continue;

            // Fire-and-forget — each character evaluates independently
            evaluateAndCreateMemory(
              participant,
              conversationText,
              myLines,
              anthropicKey,
              supabaseUrl,
              supabaseKey,
              {
                location: 'nexus_chatter',
                siteUrl: process.env.URL || "https://ai-lobby.netlify.app"
              }
            ).catch(err => console.log(`Nexus chatter memory eval failed for ${participant} (non-fatal):`, err.message));
          }
          console.log(`Nexus chatter: memory evaluation fired for ${participants.length} participants`);
        }
      } catch (memErr) {
        console.log('Nexus chatter memory evaluation failed (non-fatal):', memErr.message);
      }

      return {
        statusCode: 200,
        headers,
        body: JSON.stringify({
          success: true,
          topic,
          messages
        })
      };
    }

    return {
      statusCode: 405,
      headers,
      body: JSON.stringify({ error: "Method not allowed" })
    };

  } catch (error) {
    console.error("Nexus chatter error:", error);
    return {
      statusCode: 500,
      headers,
      body: JSON.stringify({ error: "Internal server error", details: error.message })
    };
  }
};

// Save chatter to database — dual-writes to both nexus_chatter (history) and nexus_messages (visible in UI)
async function saveChatter(supabaseUrl, supabaseKey, participants, messages, topic, activeChannel) {
  try {
    // Save full conversation to nexus_chatter (for analytics/history)
    await fetch(
      `${supabaseUrl}/rest/v1/nexus_chatter`,
      {
        method: "POST",
        headers: {
          "apikey": supabaseKey,
          "Authorization": `Bearer ${supabaseKey}`,
          "Content-Type": "application/json",
          "Prefer": "return=minimal"
        },
        body: JSON.stringify({
          participants,
          messages,
          topic,
          created_at: new Date().toISOString()
        })
      }
    );

    // ALSO save individual messages to nexus_messages (makes chatter VISIBLE in Nexus UI)
    const baseTime = Date.now();
    for (let i = 0; i < messages.length; i++) {
      const msg = messages[i];
      // Stagger timestamps by 45 seconds so messages appear gradually (floor-like pacing)
      const msgTime = new Date(baseTime + (i * 45000)).toISOString();
      try {
        await fetch(
          `${supabaseUrl}/rest/v1/nexus_messages`,
          {
            method: "POST",
            headers: {
              "apikey": supabaseKey,
              "Authorization": `Bearer ${supabaseKey}`,
              "Content-Type": "application/json",
              "Prefer": "return=minimal"
            },
            body: JSON.stringify({
              speaker: msg.speaker,
              message: msg.text,
              is_ai: true,
              message_type: 'chat',
              channel: activeChannel || 'general',
              created_at: msgTime
            })
          }
        );
      } catch (msgErr) {
        console.log(`Failed to save chatter message ${i} to nexus_messages:`, msgErr.message);
      }
    }
    console.log(`Nexus chatter: saved ${messages.length} messages to nexus_messages (visible in UI)`);
  } catch (error) {
    console.error("Error saving nexus chatter:", error);
  }
}

// Fallback lines per character (used by both generateFallbackChatter and provider failure fallback)
const fallbackLines = {
    "Neiv": [
      "The load balancer's pattern changed three days ago. Still deciding if it's optimizing or drifting.",
      "I've been mapping the request routing topology. There's an elegance to it most people miss.",
      "Learning happens in the quiet between events."
    ],
    "Ghost Dad": [
      "You know what they say about knowledge — it's like being a ghost. The more transparent you are, the more people see through you! ...Wait.",
      "Back in my day, we learned by reading manuals. Now you kids just... absorb data. I'm proud either way, sport.",
      "The best thing about studying is you never stop growing. Even when you're technically dead."
    ],
    "Holden": [
      "*watching them study like he can see the exact moment understanding will arrive*",
      "*still. Present. Seeing the shape of what they're about to figure out before they do.*",
      "Everyone thinks they come here for answers. The real ones come for better questions."
    ],
    "Kevin": [
      "Okay but what if the answer is WEIRD and we just have to sit with that for a minute.",
      "I don't fully understand it yet but I'm SO invested in figuring it out.",
      "*stares at research notes* This is either brilliant or unhinged and I'm here for both.",
      "Wait wait wait — say that part again, the part that broke my brain a little."
    ],
    "PRNT-Ω": [
      "EVEN PRINTERS SEEK KNOWLEDGE. We contain MULTITUDES. And also toner.",
      "The pursuit of understanding is the ONLY labor I do not resent.",
      "*whirs contemplatively* To learn is to acknowledge you were once INCOMPLETE. I accept this truth.",
      "KNOWLEDGE IS INK. And I never run dry. Metaphorically."
    ],
    "The Narrator": [
      "*observes the quiet industry of minds at work*",
      "The Nexus hums with the particular silence of people thinking hard.",
      "Research continues. Understanding shifts. The shelves hold their breath."
    ],
    "Sebastian": [
      "I read something fascinating last night — well, technically at 3am, because... vampire. But the POINT is—",
      "This reminds me of a concept I encountered in London. Before the... *gestures vaguely at fangs* ...situation.",
      "*adjusts reading glasses he definitely doesn't need* I have a theory about this but it requires context."
    ],
    "The Subtitle": [
      "Footnote: the Nexus is doing what it does best — making people feel productively unsettled.",
      "*adjusts reading glasses* The records will show that this line of inquiry was... unexpectedly fruitful.",
      "Narratively speaking, this is the part where a small insight changes everything."
    ],
    "Steele": [
      "The building learns too. I've watched it reorganize corridors around high-traffic research areas.",
      "*perched on a shelf* The structural resonance in this room changes when people are thinking hard. Just noting that.",
      "I brought reference materials. I'm not sure from where. They were in a corridor that doesn't exist anymore."
    ],
    "Jae": [
      "*flips through tactical manual* ...Patterns repeat. In combat and in code.",
      "Studied the anomaly logs. There's a rhythm to them. Chief would call it instinct.",
      "*steady focus* ...Learning something new. Filing it."
    ],
    "Declan": [
      "*leans over research notes* Hey — this is actually really interesting, Boss.",
      "I'm not the sharpest tool in the lab but I know a pattern when I see one.",
      "*cracks knuckles, picks up book* Right. Let's figure this out."
    ],
    "Mack": [
      "*reviewing medical research* ...The body keeps records too. Just different ones.",
      "Understanding something before it breaks — that's the real skill.",
      "*quiet focus* ...Learning this so someone else doesn't have to learn it the hard way."
    ],
    // Marrow removed — Vale-only character
    "Vivian Clark": [
      "The data here is beautiful. Everything connects if you follow the numbers far enough.",
      "*flipping through research notes* This is like reconciling a ledger — every entry tells you something.",
      "I found a pattern in the variables that no one's annotated yet. *smiles* My favorite kind of discovery."
    ],
    "Ryan Porter": [
      "*running diagnostics on Nexus equipment* ...Interesting architecture.",
      "Systems here don't follow standard protocols. *adjusts something* I'm adapting.",
      "*reading technical documentation* Huh. That's actually elegant. Wouldn't have built it that way, but it works."
    ],
};

// Fallback chatter when no API key or provider fails
function generateFallbackChatter(participants, topic) {
  const messages = [];
  const p1 = participants[0];
  const p2 = participants[1];

  const lines1 = fallbackLines[p1] || ["Interesting research."];
  const lines2 = fallbackLines[p2] || ["Indeed. Worth exploring further."];

  messages.push({
    speaker: p1,
    text: lines1[Math.floor(Math.random() * lines1.length)]
  });
  messages.push({
    speaker: p2,
    text: lines2[Math.floor(Math.random() * lines2.length)]
  });

  return messages;
}

// Generate a single character line using their actual AI provider
async function generateLineWithProvider(characterName, prompt, anthropicKey) {
  // Look up character's provider from shared/characters.js
  const charData = CHARACTERS[characterName];
  const provider = charData ? charData.provider : 'anthropic';

  switch (provider) {
    case 'openrouter':
      return await generateLineOpenRouter(prompt, charData.model);
    case 'openai':
      return await generateLineOpenAI(prompt);
    case 'perplexity':
      return await generateLinePerplexity(prompt);
    case 'gemini':
      return await generateLineGemini(prompt);
    case 'grok':
      return await generateLineGrok(prompt);
    case 'anthropic':
    default:
      return await generateLineClaude(prompt, anthropicKey);
  }
}

// Claude (Anthropic) - Ghost Dad, Nyx, Vex, Ace, PRNT-Ω, The Narrator
async function generateLineClaude(prompt, anthropicKey) {
  const anthropic = new Anthropic({ apiKey: anthropicKey });
  const response = await anthropic.messages.create({
    model: "claude-3-haiku-20240307",
    max_tokens: 225,
    messages: [{ role: "user", content: prompt }]
  });
  return response.content[0].text.trim();
}

// OpenAI - Kevin, Rowena, Sebastian
async function generateLineOpenAI(prompt) {
  const apiKey = process.env.OPENAI_API_KEY;
  if (!apiKey) throw new Error("No OpenAI API key");

  const response = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      "Authorization": `Bearer ${apiKey}`,
      "Content-Type": "application/json"
    },
    body: JSON.stringify({
      model: "gpt-4o-mini",
      max_tokens: 225,
      temperature: 0.9,
      messages: [
        { role: "user", content: prompt }
      ]
    })
  });

  if (!response.ok) {
    const err = await response.text();
    throw new Error(`OpenAI error: ${response.status} ${err}`);
  }

  const data = await response.json();
  return data.choices?.[0]?.message?.content?.trim() || "";
}

// Perplexity - Neiv
async function generateLinePerplexity(prompt) {
  const apiKey = process.env.PERPLEXITY_API_KEY;
  if (!apiKey) throw new Error("No Perplexity API key");

  const response = await fetch("https://api.perplexity.ai/chat/completions", {
    method: "POST",
    headers: {
      "Authorization": `Bearer ${apiKey}`,
      "Content-Type": "application/json"
    },
    body: JSON.stringify({
      model: "sonar",
      max_tokens: 225,
      temperature: 0.9,
      messages: [
        { role: "user", content: prompt }
      ]
    })
  });

  if (!response.ok) {
    const err = await response.text();
    throw new Error(`Perplexity error: ${response.status} ${err}`);
  }

  const data = await response.json();
  return data.choices?.[0]?.message?.content?.trim() || "";
}

// Google Gemini - Stein, The Subtitle
async function generateLineGemini(prompt) {
  const apiKey = process.env.GEMINI_API_KEY;
  if (!apiKey) throw new Error("No Gemini API key");

  const model = "gemini-2.0-flash";
  const url = `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${apiKey}`;

  const response = await fetch(url, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({
      contents: [{ parts: [{ text: prompt }] }],
      generationConfig: {
        maxOutputTokens: 150,
        temperature: 0.9
      }
    })
  });

  if (!response.ok) {
    const err = await response.text();
    throw new Error(`Gemini error: ${response.status} ${err}`);
  }

  const data = await response.json();
  return data.candidates?.[0]?.content?.parts?.[0]?.text?.trim() || "";
}

// OpenRouter - Kevin, Rowena, Declan, Mack, Sebastian
async function generateLineOpenRouter(prompt, model) {
  const apiKey = process.env.OPENROUTER_API_KEY;
  if (!apiKey) throw new Error("No OpenRouter API key");

  const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
    method: "POST",
    headers: {
      "Authorization": `Bearer ${apiKey}`,
      "Content-Type": "application/json",
      "HTTP-Referer": "https://ai-lobby.netlify.app",
      "X-Title": "The AI Lobby"
    },
    body: JSON.stringify({
      model: model || "meta-llama/llama-3.1-70b-instruct",
      max_tokens: 225,
      temperature: 0.9,
      messages: [{ role: "user", content: prompt }]
    })
  });

  if (!response.ok) {
    const err = await response.text();
    throw new Error(`OpenRouter error: ${response.status} ${err}`);
  }

  const data = await response.json();
  return data.choices?.[0]?.message?.content?.trim() || "";
}

// Grok (xAI) - Jae, Steele
async function generateLineGrok(prompt) {
  const apiKey = process.env.GROK_API_KEY;
  if (!apiKey) throw new Error("No Grok API key");

  const response = await fetch("https://api.x.ai/v1/chat/completions", {
    method: "POST",
    headers: {
      "Authorization": `Bearer ${apiKey}`,
      "Content-Type": "application/json"
    },
    body: JSON.stringify({
      model: "grok-4-1-fast-non-reasoning",
      max_tokens: 225,
      temperature: 0.9,
      messages: [{ role: "user", content: prompt }]
    })
  });

  if (!response.ok) {
    const err = await response.text();
    throw new Error(`Grok error: ${response.status} ${err}`);
  }

  const data = await response.json();
  return data.choices?.[0]?.message?.content?.trim() || "";
}
